{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1Z19yUV06JxGlzTkVjb6Uu-C9CBzk109v",
      "authorship_tag": "ABX9TyNk9qqmGAnTPHlmcZebbbHI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/enzocfb/general/blob/main/eda_2023_deductivos_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1iOsCEHHAGK"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Analisis de Deductivos para analizar causas\n",
        "Impacto :\n",
        "\n",
        "input:\n",
        "      Consolidato total de Evaluados por UGS(Formato 06) para todos los años\n",
        "        Consolidado que contiene los portafolios : 2024-02 , 2024-01, 2023-01 , 2022-02\n",
        "\n",
        "      Deductivos reportados por UGT\n",
        "      Fechas referenciales por grupos\n",
        "\n",
        "output:\n",
        "      Consolidado de evaluados, y su estado : \"Deductivo\", y \"No Deductivo\"\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "FiMZJKHXIFWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####################################################3\n",
        "# Input\n",
        "####################################################3\n",
        "\n",
        "# Archivo completo de las evaluaciones realizadas por UGS, a partir de la cual se extrae la informacion del beneficiario,\n",
        "# # Alcance : REGISTRADO- desde que se inicia en ESTADO REGISTRADO, LUEGO A ESTADO EVALUADO , luego  ESTADO VIABILIDAD y finalmente # a ESTADO DE DEDUCTIVIDAD\n",
        "# KEY or INDICE del ARCHIVO:   CUV (Codigo que contiene el UIBGEO del CENTRO POBLADO + DNI del JEFE + AñO + NRO PORTAFOLIO)\n",
        "#                              CONVENIO,  es una agrupacion de Beneficiarios (FALTA, no tiene en este momento esa data)\n",
        "\n",
        "file = '/content/drive/MyDrive/@@@Dev/mvcs/Data/Formato06Completo.xlsx'\n",
        "\n",
        "# 2. ARCHIVO DE DEDUCTIVOS (BENEFICIARIO QUE ESTA EN ESTADO = \"DEDUCTIVO\", es aquel que \"SE EXCLUYE\" DEL PROGRAMA. Este archivo es recibido de  UGT que contiene la informacion de todos aquellos que fueron\n",
        "# ALCANCE : VIABLE-->DEDUCTIVO\n",
        "# KEY or INDICE del ARCHIVO:\n",
        "#                              CUV (Codigo que contiene el UIBGEO del CENTRO POBLADO + DNI del JEFE + AñO + NRO PORTAFOLIO) (SI TIENE)\n",
        "#                              CONVENIO,  es una agrupacion de Beneficiarios,                                               (SI TIENE)\n",
        "\n",
        "file_deductivos= '/content/drive/MyDrive/@@@Dev/mvcs/Data/LISTADO DE DEDUCTIVOS A (UGS).xlsx'\n",
        "\n",
        "\n",
        "# Informacion a nivel de nucleos de las fechas de exp tecnico y fecha de Acta de inicio de Construccion\n",
        "# Alcance : REGISTRADO-->EVALUADO-->VIABLE (TODOs: ESTADO_VIABLE = \"VIABLE\", INCLUIDO ESTADO_DEDUCTIVO = {\"DEDUCTIVO\", \"NO DEDUCTIVO\"] se une a nivel con archivo 2, con los\n",
        "# 17 nov : Solo se tienen info para VIABLE-->DEDUCTIVO, falta a nivel de todos los VIABLES.\n",
        "# KEY or INDICE del ARCHIVO:   CONVENIO,  es una agrupacion de Beneficiarios, (SI TIENE)\n",
        "\n",
        "file_input_nucleo = '/content/drive/MyDrive/@@@Dev/mvcs/Data/NUCLEO - REPORTE COMPLEMENTARIO.xlsx'\n",
        "file_input_2020_02 = '/content/drive/MyDrive/@@@Dev/mvcs/Data/Pnvr_formato06_20231122-15.57.07.xlsx'\n",
        "\n",
        "file_base_total_consolidado = '/content/drive/MyDrive/@@@Dev/mvcs/Data/Base Total Usuarios del PNVR_v7_20.11.23.xlsx'\n",
        "\n",
        "\n",
        "\n",
        "####################################################3\n",
        "# Output\n",
        "####################################################3\n",
        "# output temporales\n",
        "file_output_1 = '/content/drive/MyDrive/@@@Dev/mvcs/Data/CUVs no encontrados.xlsx'\n",
        "file_output_2 = '/content/drive/MyDrive/@@@Dev/mvcs/Data/CUVs si encontrados.xlsx'\n",
        "\n",
        "\n",
        "file_temp_1 = '/content/drive/MyDrive/@@@Dev/mvcs/Data/temp_1.xlsx'\n",
        "file_temp_2 = '/content/drive/MyDrive/@@@Dev/mvcs/Data/temp_2.xlsx'\n",
        "file_output_3 = '/content/drive/MyDrive/@@@Dev/mvcs/Data/temp_3.xlsx'\n",
        "\n",
        "# output\n",
        "file_output_analisis = '/content/drive/MyDrive/@@@Dev/mvcs/Data/deductivos-completo-analysis.xlsx'\n",
        "\n",
        "\n",
        "# Constantes\n",
        "constante_origen_PP068 = 'PP068'   # NUMERO DEL PROGRAMA ORIGEN\n",
        "\n",
        "# Creamos ESTADOS : REGISTRADO, EVALUACION,  VIABILIDAD,\n",
        "constante_estado_registrado = 'REGISTRADO'\n",
        "\n",
        "constante_estado_evaluacion_evaluado = \"EVALUADO\"\n",
        "constante_estado_evaluacion_rechaza = \"RECHAZA_EVALUACION\"\n",
        "constante_estado_evaluacion_otros = 'OTROS_NO_EVALUADO'\n",
        "\n",
        "constante_estado_viabilidad_viable = \"VIABLE\"\n",
        "constante_estado_viabilidad_no_viable = \"NO VIABLE\"\n",
        "constante_estado_sininfo = \"SIN INFORMACION\"\n",
        "constante_estado_viabilidad_social_viable = 'SOCIALMENTE VIABLE'\n",
        "constante_estado_viabilidad_social_no_viable = 'NO VIABLE SOCIALMENTE'\n",
        "\n",
        "constante_estado_SI = \"SI\"\n",
        "constante_estado_SI = \"NO\"\n",
        "\n",
        "\n",
        "constante_estado_deductivo = \"DEDUCTIVO\"\n",
        "constante_estado_no_deductivo = \"NO_DEDUCTIVO\"\n",
        "\n",
        "# Mejoras\n",
        "# Definir Estructura UGS\n",
        "# Definir Estructura UGS + UGT\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "I0gWRnReICcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "QNg8Gr79MOxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_date(value):\n",
        "    try:\n",
        "        return pd.to_datetime(value)\n",
        "    except ValueError:\n",
        "        # Handle the case where parsing the date fails\n",
        "        return value\n",
        "\n",
        "# # Read the Excel file with the converters parameter\n",
        "# df = pd.read_excel(file, converters={\"Your_Column_Name\": convert_to_date})"
      ],
      "metadata": {
        "id": "A9uKBDfRQqqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# La hoja excel, original se le transforma para poder ser leida\n",
        "# Combinar celdas\n",
        "# subir fila 6,\n",
        "# bajamos los nombre de capos de la fila 5 a fila 6 (solo los que faltan)\n",
        "\n",
        "\n",
        "df = pd.read_excel(file, converters={\"CODIGO_CCPP\": str, \"UBIGEO\": str})\n",
        "# df = pd.read_excel(file, converters={\"CODIGO_CCPP\": str, \"UBIGEO\": str, \"FEC_EVALUACION\": convert_to_date})\n",
        "df.head(3)\n",
        "\n",
        "# CREACION DE ESTADOS PARA TABLA INICIAL\n",
        "\n"
      ],
      "metadata": {
        "id": "yDrqg2phIHp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "mrhdZlcHZqSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleccionar campos requeridos para el analisis y construir las features\n",
        "\n",
        "columns_selected_df = ['NUMERO', 'ORIGEN', 'PORTAFOLIO_T', 'CUV', 'CODIGO_CCPP', 'UBIGEO', 'DEPARTAMENTO','PROVINCIA', 'DISTRITO', 'CENTRO_POBLADO', 'COMUNIDAD', 'PATERNO_JEFE_HOGAR', 'NOMBRES_JEFE_HOGAR', 'DNI_JEFE_HOGAR', 'SEXO_JEFE_HOGAR', 'EDAD_JEFE_HOGAR', 'FEC_NAC_JEFE_HOGAR', 'CANT', 'CTD_DISCAPACIDAD', 'ALTURA', 'LATITUD', 'LONGITUD', 'CLASIFICACION_SOCIOECONOMICA_CSE', 'VIABILIDAD_TOTAL', 'VIABILIDAD_SOCIAL', 'VIABILIDAD_TECNICA','DNI_CYG','ACEPTA_ENTREVISTA', 'CRITERIO_SOCIAL', 'CRITERIO_TECNICO', 'FEC_EVALUACION', 'FECHA_CONSULTA_CSE']\n",
        "df = df[columns_selected_df]\n",
        "\n",
        "# renonmbar dni coyg por DNI_CYG\n",
        "\n",
        "columns_selected_df_2020_02 = ['CODIGO CUV', 'DEPARTAMENTO', 'PROVINCIA', 'DISTRITO',\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t'CENTRO POBLADO', 'COMUNIDAD', 'PATERNO', 'MATERNO', 'NOMBRES', 'DNI', 'SEXO',\n",
        "                               'ALTURA','LATITUD', 'LONGITUD', 'DETERMINACIÓN DE LA VIABILIDAD', 'CRITERIO SOCIAL', 'CRITERIO TÉCNICO',\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t'VIABILIDAD SOCIAL', 'VIABILIDAD TECNICA',\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t'DNI_CYG',\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t'CLASIFICACION SOCIOECONOMICA CSE'\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t]\n",
        "\n"
      ],
      "metadata": {
        "id": "Gx2R_x8i3nzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TcWdPHJYX3xc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############################################################3\n",
        "# Crear base unica, a partir de base consolidada y formato06\n",
        "###############################################################################\n"
      ],
      "metadata": {
        "id": "X_0A0PCfBLU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_deductivos_faltante = rows_not_in_df06\n",
        "\n",
        "df = pd.read_excel(file)\n",
        "df = df[columns_selected_df]\n",
        "\n",
        "# el campo CUV, tiene vacios, pero el campo DNI, no asi que lo elegimos como clave\n",
        "# para ello verifricamos si este campo tiene duplicados\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GDVnX-0DJwR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Counting duplicated values in the 'Name' column\n",
        "duplicates_count = df.duplicated(subset='DNI_JEFE_HOGAR').sum()\n",
        "\n",
        "# Displaying the DataFrame and the count of duplicated values\n",
        "# print(\"Original DataFrame:\")\n",
        "# print(df.head(2))\n",
        "\n",
        "print(\"\\nCount of duplicated values in the 'Name' column:\", duplicates_count)\n",
        "# Count of duplicated values in the 'Name' column: 6737\n",
        "\n",
        "# Se descarta dni como clave y solo se usa CUV, para ello elinamos los CUV que estan vacios\n",
        "\n"
      ],
      "metadata": {
        "id": "9fQsCME1Z-SW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.shape[0])\n",
        "# Dropping rows where the 'Name' column is null\n",
        "df_cleaned = df.dropna(subset=['CUV'], inplace = True)\n",
        "print(df.shape[0])"
      ],
      "metadata": {
        "id": "pW4_Opu7dcqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_base_consolidada = pd.read_excel(file_base_total_consolidado)\n",
        "df_base_consolidada.head(3)\n",
        "\n",
        "columns_selected_df_base = [ 'OBJECTID', 'CUV', 'Ubigeo CP', 'Ubigeo', 'Departamento', 'Provincia', 'Distrito', 'Centro Poblado', 'Comunidad', 'Ape. Paterno', 'Ape. Materno', 'Nombre', 'DNI', 'Sexo', 'edad', 'Fecha de Nacimiento',\n",
        "                            'Número de Miembros', 'altitud', 'latitud', 'longitud']\n",
        "\n",
        "new_columns_to_add = ['NUMERO', 'ORIGEN', 'PORTAFOLIO_T', 'CLASIFICACION_SOCIOECONOMICA_CSE', 'VIABILIDAD_TOTAL', 'VIABILIDAD_SOCIAL', 'VIABILIDAD_TECNICA',\n",
        "                      'ACEPTA_ENTREVISTA', 'CRITERIO_SOCIAL', 'CRITERIO_TECNICO', 'FEC_EVALUACION', 'FECHA_CONSULTA_CSE']\n",
        "\n",
        "df_base = df_base_consolidada[columns_selected_df_base]"
      ],
      "metadata": {
        "id": "xeCVIfBXL33x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w0SfW4m_fORY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  # Add empty columns to the DataFrame\n",
        "  for col_name in new_columns_to_add:\n",
        "      df_base[col_name] = None"
      ],
      "metadata": {
        "id": "beF9aXNWfwYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_base.info()"
      ],
      "metadata": {
        "id": "ELkq1GwXg_Vq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nY6cCQiThBTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# renombar las columnas campos segun el df padre : df:\n",
        "# ================================================================\n",
        "\n",
        "df_base.rename(columns={'Ubigeo CP': 'CODIGO_CCPP'}, inplace=True)\n",
        "df_base.rename(columns={'Ubigeo': 'UBIGEO'}, inplace=True)\n",
        "df_base.rename(columns={'Departamento': 'DEPARTAMENTO'}, inplace=True)\n",
        "df_base.rename(columns={'Provincia': 'PROVINCIA'}, inplace=True)\n",
        "df_base.rename(columns={'Distrito': 'DISTRITO'}, inplace=True)\n",
        "df_base.rename(columns={'Centro Poblado': 'CENTRO_POBLADO'}, inplace=True)\n",
        "df_base.rename(columns={'Comunidad': 'COMUNIDAD'}, inplace=True)\n",
        "df_base.rename(columns={'Ape. Paterno': 'PATERNO_JEFE_HOGAR'}, inplace=True)\n",
        "df_base.rename(columns={'Ape. Materno': 'MATERNO_JEFE_HOGAR'}, inplace=True)\n",
        "df_base.rename(columns={'Nombre': 'NOMBRES_JEFE_HOGAR'}, inplace=True)\n",
        "\n",
        "df_base.rename(columns={'DNI': 'DNI_JEFE_HOGAR'}, inplace=True)\n",
        "df_base.rename(columns={'Sexo': 'SEXO_JEFE_HOGAR'}, inplace=True)\n",
        "df_base.rename(columns={'edad': 'EDAD_JEFE_HOGAR'}, inplace=True)\n",
        "df_base.rename(columns={'Fecha de Nacimiento': 'FEC_NAC_JEFE_HOGAR'}, inplace=True)\n",
        "df_base.rename(columns={'Número de Miembros': 'CANT'}, inplace=True)\n",
        "df_base.rename(columns={'altitud': 'ALTURA'}, inplace=True)\n",
        "df_base.rename(columns={'latitud': 'LATITUD'}, inplace=True)\n",
        "df_base.rename(columns={'longitud': 'LONGITUD'}, inplace=True)"
      ],
      "metadata": {
        "id": "JZBnGgSNc9XW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_base_with_f06_inner = pd.merge(df_base, df, on = 'CUV', suffixes={'_BASE', '_F06'})"
      ],
      "metadata": {
        "id": "4AlHOmlpG6kd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_base_with_f06_inner.to_excel(file_temp_1)"
      ],
      "metadata": {
        "id": "qMwrfvxnHX-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_base_with_f06_outer = pd.merge(df_base, df, on = 'CUV', how = 'outer', suffixes={'_BASE', '_F06'})"
      ],
      "metadata": {
        "id": "8ihY-GnER81P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_base_with_f06_outer.to_excel(file_temp_2)"
      ],
      "metadata": {
        "id": "uvIHTHW-R892"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_base_with_f06_inner.head()"
      ],
      "metadata": {
        "id": "o4B7wc4MUiYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_base_with_f06_inner.shape[0])\n",
        "print(df_base_with_f06_outer.shape[0])"
      ],
      "metadata": {
        "id": "GHBPwI7PTnl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  # =============================================================================================\n",
        "  # POST : Crear los Estados\n",
        "  #================================================================================================\n",
        "\n",
        "  # reglas para llenar los campos faltantes, derivados de informacion existente\n",
        "  # Se llenan de esta forma, porque ya son DEDUCTIVOS, es decir han pasado por todas las etapas desde ser registrados, evaluados, y viables.\n",
        "  # viabilidad, considerando que todos los deductivos, previaente fueron REGISTRADOS, luego EVALUADOS, y luego viables, entonces se coloca el valor VIABLE , lara todos los registros\n",
        "  #\n",
        "\n",
        "  df_deductivos_en_base['ESTADO_REGISTRADO'] = constante_estado_registrado\n",
        "  df_deductivos_en_base['ESTADO_EVALUACION'] = constante_estado_evaluacion_evaluado\n",
        "  df_deductivos_en_base['ESTADO_VIABLE'] = constante_estado_viabilidad_viable\n",
        "  df_deductivos_en_base['ESTADO_DEDUCTIVO'] = constante_estado_deductivo\n",
        "\n",
        "\n",
        "  df_deductivos_en_base['VIABILIDAD_TOTAL'] = constante_estado_viabilidad_viable\n",
        "  df_deductivos_en_base['VIABILIDAD_SOCIAL'] = constante_estado_viabilidad_social_viable\n",
        "  df_deductivos_en_base['VIABILIDAD_TECNICA'] = constante_estado_viabilidad_viable\n",
        "\n",
        "\n",
        "  # Campos adicionados con logica\n",
        "\n",
        "\n",
        "\n",
        "  # ============================================\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LMizU1LIkFaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ver que otros campos de deductivos, deben ser tomados para completar segun salida de analisis?_deductivos.xlsx\n"
      ],
      "metadata": {
        "id": "3TtwpeU4oX08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Creating two sample DataFrames\n",
        "df1 = pd.DataFrame({'key': ['A', 'B', 'C', 'D'],\n",
        "                    'value': [1, 2, 3, 4]})\n",
        "\n",
        "df2 = pd.DataFrame({'key': ['B', 'D', 'E', 'F'],\n",
        "                    'value': [5, 6, 7, 8]})\n",
        "\n",
        "\n",
        "print(df1)\n",
        "\n",
        "print(df2)\n"
      ],
      "metadata": {
        "id": "H7JQtYt_TH5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inner merge\n",
        "inner_merged = pd.merge(df1, df2, how='inner', on='key')\n",
        "print(\"Inner Merge:\")\n",
        "print(inner_merged)\n",
        "\n",
        "# Left merge\n",
        "left_merged = pd.merge(df1, df2, how='left', on='key')\n",
        "print(\"\\nLeft Merge:\")\n",
        "print(left_merged)\n",
        "\n",
        "# Right merge\n",
        "right_merged = pd.merge(df1, df2, how='right', on='key')\n",
        "print(\"\\nRight Merge:\")\n",
        "print(right_merged)\n",
        "\n",
        "# Outer merge\n",
        "outer_merged = pd.merge(df1, df2, how='outer', on='key')\n",
        "print(\"\\nOuter Merge:\")\n",
        "print(outer_merged)"
      ],
      "metadata": {
        "id": "2MweWBtnTPaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Creating a sample DataFrame\n",
        "data = {'Name': ['Alice', 'Alice', 'Charlie', 'Alice', 'David'],\n",
        "        'Age': [25, 30, 35, 25, 40],\n",
        "        'City': ['New York', 'San Francisco', 'Los Angeles', 'New York', 'Seattle']}\n",
        "\n",
        "df3 = pd.DataFrame(data)\n",
        "\n",
        "df3\n"
      ],
      "metadata": {
        "id": "ZRqlk8KyZWK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Counting duplicated values in the 'Name' column\n",
        "duplicates_count = df3.duplicated(subset='Name').sum()\n",
        "\n",
        "# Displaying the DataFrame and the count of duplicated values\n",
        "print(\"Original DataFrame:\")\n",
        "print(df3)\n",
        "\n",
        "print(\"\\nCount of duplicated values in the 'Name' column:\", duplicates_count)"
      ],
      "metadata": {
        "id": "z2lxP9lsZbP4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}